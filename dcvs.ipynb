{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d65b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../harvard/repos/dcv-python/32.pickle', 'rb') as handle:\n",
    "    dcvs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a0c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ids = list(dcvs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fe7d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yazatian/Library/Caches/pypoetry/virtualenvs/dcv-python-ytIwIEW1-py3.9/lib/python3.9/site-packages/fastbook/__init__.py:19: UserWarning: Missing `graphviz` - please run `conda install fastbook`\n",
      "  except ModuleNotFoundError: warn(\"Missing `graphviz` - please run `conda install fastbook`\")\n"
     ]
    }
   ],
   "source": [
    "from fastbook import tensor, show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3094b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a89c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../harvard/repos/dcv-python/dcvs.pickle', 'rb') as handle:\n",
    "    real_image = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47800f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_circular_mask(h, w, center=None, radius=None):\n",
    "\n",
    "    if center is None: # use the middle of the image\n",
    "        center = (int(w/2), int(h/2))\n",
    "    if radius is None: # use the smallest distance between the center and image walls\n",
    "        radius = min(center[0], center[1], w-center[0], h-center[1])\n",
    "\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1181d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "circular_mask = create_circular_mask(40,40, radius=12.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "520d8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cutouts = {}\n",
    "for x in _ids:\n",
    "    final_cutouts[x] = np.where(circular_mask==1, real_image[x], circular_mask)[4:36,4:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5f88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_embedding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc1d7483",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "labels = []\n",
    "for key, value in dcvs.items():\n",
    "    train_dataset.append(tensor(np.expand_dims(np.float32(value), axis=0)))\n",
    "    labels.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0031516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_id = {}\n",
    "for i, x in enumerate(train_dataset):\n",
    "    img_to_id[np.array(x).tobytes()] = labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13fdeece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8ccb5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2359120"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2062ca8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the seed\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3809ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_torch = torch.stack(train_dataset) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25c11889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42162, 1, 32, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2ccf5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_torch.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1f66d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = torch.utils.data.random_split(train_dataset_torch, \n",
    "                                                             [33730, 4216, 4216], \n",
    "                                                             generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d62fa4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33730"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "999d2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "training_steps = 5000\n",
    "train_batch_size = 8\n",
    "holdout_batch_size = 1\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6098c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "#pin_memory=True\n",
    "train_loader = DataLoader(train_set, batch_size=train_batch_size)\n",
    "val_loader = DataLoader(val_set, batch_size=holdout_batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=holdout_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a21532f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0].shape[-1:None:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65d741a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE(input_size=train_set[0].shape[-1:None:-1],depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a41f02c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d513f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54f4614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcc68c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             640\n",
      "    InstanceNorm2d-2           [-1, 64, 32, 32]               0\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "              ReLU-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,928\n",
      "    InstanceNorm2d-6           [-1, 64, 32, 32]               0\n",
      "              ReLU-7           [-1, 64, 32, 32]               0\n",
      "              ReLU-8           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-9           [-1, 64, 16, 16]               0\n",
      "           Conv2d-10          [-1, 128, 16, 16]          73,856\n",
      "   InstanceNorm2d-11          [-1, 128, 16, 16]               0\n",
      "             ReLU-12          [-1, 128, 16, 16]               0\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "           Conv2d-14          [-1, 128, 16, 16]         147,584\n",
      "   InstanceNorm2d-15          [-1, 128, 16, 16]               0\n",
      "             ReLU-16          [-1, 128, 16, 16]               0\n",
      "             ReLU-17          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-18            [-1, 128, 8, 8]               0\n",
      "           Conv2d-19            [-1, 256, 8, 8]         295,168\n",
      "   InstanceNorm2d-20            [-1, 256, 8, 8]               0\n",
      "             ReLU-21            [-1, 256, 8, 8]               0\n",
      "             ReLU-22            [-1, 256, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]         590,080\n",
      "   InstanceNorm2d-24            [-1, 256, 8, 8]               0\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "             ReLU-26            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-27            [-1, 256, 4, 4]               0\n",
      "          Flatten-28                 [-1, 4096]               0\n",
      "           Linear-29                    [-1, 8]          32,776\n",
      "           Linear-30                 [-1, 4096]          36,864\n",
      "        Unflatten-31            [-1, 256, 4, 4]               0\n",
      "         Upsample-32            [-1, 256, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]         590,080\n",
      "   InstanceNorm2d-34            [-1, 256, 8, 8]               0\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "             ReLU-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]         295,040\n",
      "   InstanceNorm2d-38            [-1, 128, 8, 8]               0\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "             ReLU-40            [-1, 128, 8, 8]               0\n",
      "         Upsample-41          [-1, 128, 16, 16]               0\n",
      "           Conv2d-42          [-1, 128, 16, 16]         147,584\n",
      "   InstanceNorm2d-43          [-1, 128, 16, 16]               0\n",
      "             ReLU-44          [-1, 128, 16, 16]               0\n",
      "             ReLU-45          [-1, 128, 16, 16]               0\n",
      "           Conv2d-46           [-1, 64, 16, 16]          73,792\n",
      "   InstanceNorm2d-47           [-1, 64, 16, 16]               0\n",
      "             ReLU-48           [-1, 64, 16, 16]               0\n",
      "             ReLU-49           [-1, 64, 16, 16]               0\n",
      "         Upsample-50           [-1, 64, 32, 32]               0\n",
      "           Conv2d-51           [-1, 64, 32, 32]          36,928\n",
      "   InstanceNorm2d-52           [-1, 64, 32, 32]               0\n",
      "             ReLU-53           [-1, 64, 32, 32]               0\n",
      "             ReLU-54           [-1, 64, 32, 32]               0\n",
      "           Conv2d-55            [-1, 1, 32, 32]             577\n",
      "   InstanceNorm2d-56            [-1, 1, 32, 32]               0\n",
      "             ReLU-57            [-1, 1, 32, 32]               0\n",
      "             ReLU-58            [-1, 1, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 2,357,897\n",
      "Trainable params: 2,357,897\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 12.47\n",
      "Params size (MB): 8.99\n",
      "Estimated Total Size (MB): 21.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size=train_set[0].shape)\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "writer = SummaryWriter(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446e4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "497d832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2d5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "996957bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "488eaeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.unsqueeze(train_dataset[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine embedding loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7fb126c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44aa33201f741f1ac937d899df2200e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005212962\n",
      "0.0033876116\n",
      "0.0029022251\n",
      "0.0026324524\n",
      "0.0024601428\n",
      "0.002347675\n",
      "0.0022566274\n",
      "0.0021625764\n",
      "0.002122362\n",
      "0.002055774\n",
      "0.002000078\n",
      "0.0019413242\n",
      "0.0019012543\n",
      "0.001867778\n",
      "0.0018225302\n",
      "0.0017830794\n",
      "0.0017688064\n",
      "0.0017331024\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/autoencoder/feature_embedding/feature_embedding.py:173\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loaded, holdout_loaded, model, loss_fn, optimizer, training_steps, device, writer)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im \u001b[38;5;129;01min\u001b[39;00m tmp_val_loader:\n\u001b[1;32m    172\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 173\u001b[0m     loss_value, pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     acc_loss\u001b[38;5;241m.\u001b[39mappend(loss_value\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    175\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mholdout_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mmean(acc_loss),step)\n",
      "File \u001b[0;32m~/Desktop/autoencoder/feature_embedding/feature_embedding.py:139\u001b[0m, in \u001b[0;36mmodel_step\u001b[0;34m(model, loss_fn, optimizer, x, train_step)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# backward if training mode\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_step:\n\u001b[0;32m--> 139\u001b[0m     \u001b[43mloss_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    142\u001b[0m outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted,\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded\u001b[39m\u001b[38;5;124m'\u001b[39m: encoded,\n\u001b[1;32m    145\u001b[0m }\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/dcv-python-ytIwIEW1-py3.9/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/dcv-python-ytIwIEW1-py3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_loader, val_loader, model, loss_fn, \n",
    "      optimizer, training_steps, \n",
    "      device=device,writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69710ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "writer.close()\n",
    "\n",
    "if not(os.path.isdir(\"models\")):\n",
    "    os.mkdir(\"models\")\n",
    "\n",
    "model_name = f\"{os.path.basename(logdir)}.pth\"\n",
    "model_name_fullpath = os.path.join(\"models\",model_name)\n",
    "torch.save(model,model_name_fullpath)\n",
    "\n",
    "print(f\"Logged in: {logdir}\")\n",
    "print(f\"Model saved to: {model_name_fullpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b1830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fdb6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5a565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b7e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095fe8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72381ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
